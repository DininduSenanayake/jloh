#!/usr/bin/env python3

# version and info
script_info = """
###
Author: Matteo Schiavinato
Based on the work of: Leszek Pryszcz (2014) and Veronica Mixao (2018)
Last change: 22/12/2021
###
"""

# import modules
import argparse as ap
import os
import sys
import pysam
import subprocess
from time import asctime as at
import pybedtools
from math import log10
from pybedtools import BedTool

# help section
if len(sys.argv) == 1:
	sys.argv.append("--help")

if (sys.argv[1] in ["--help", "-h", "-help", "help", "getopt", "usage"]):
	sys.stderr.write("""

J LOH
Still the one from the block
-
Extact LOH blocks from SNPs, coverage, and a reference genome
-
v 0.7.1
--------------------------------------------------------------------------------
by Matteo Schiavinato
largely based on:
Pryszcz et al., 2014	https://doi.org/10.1093/gbe/evu082
Mixao et al., 2019		https://doi.org/10.3389/fgene.2019.00383
--------------------------------------------------------------------------------

Usage:
./jloh --vcf <VCF> --genome-file <GENOME_FILE> --bam <BAM> [options]

[mandatory]
--vcf               Input VCF file containing all types of variants             [!]
--genome-file       File with chromosome lengths (chromosome <TAB> size)        [!]
--bam               BAM file used to call the --vcf variants                    [!]

[optional]
--filter-mode       "pass" to keep only PASS variants, "all" to keep everything [all]
--sample            Sample name / Strain name for output files                  [loh_blocks]
--output-dir        Output directory                                            [loh_blocks_out]
--t0-vcf            VCF with variants to ignore from --vcf                      [off]
--t0-bam            BAM file used to call the --t0-vcf variants                 [off]
--t0-filter-type    What to do with t0 LOH events? "keep" or "remove"           [remove]
--min-het-snps      Min. num. heterozygous SNPs in heterozygous region          [2]
--snp-distance      Max. distance (bp between SNPs for blocks definition        [100]
--block-dist        Combine LOH blocks into one if closer than this distance    [100]
--min-size          Min. LOH block size                                         [100]
--min-af            Min. allele frequency to consider a variant heterozygous    [0.3]
--max-af            Max. allele frequency to consider a variant heterozygous    [0.7]
--debug             Activate generation of several intermediate files           [off]
--print-info        Show authors and edits with dates                           [off]

""")
	sys.exit(0)

# argument parser
p = ap.ArgumentParser(description="")
p.add_argument("--vcf", type=str)
p.add_argument("--bam", type=str)
p.add_argument("--genome-file")
p.add_argument("--sample", default="loh_blocks")
p.add_argument("--filter-mode", choices=["all","pass"], default="all")
p.add_argument("--output-dir", default="loh_blocks_out")
p.add_argument("--t0-vcf", type=str, default=None)
p.add_argument("--t0-bam", type=str, default=None)
p.add_argument("--t0-filter-type", choices=["keep", "remove"], default="remove")
p.add_argument("--min-het-snps", type=float, default=2)
p.add_argument("--snp-distance", default=100, type=int)
p.add_argument("--block-dist", default=100, type=int)
p.add_argument("--min-size", default=100, type=int)
p.add_argument("--min-af", default=0.3, type=float)
p.add_argument("--max-af", default=0.7, type=float)
p.add_argument("--debug", action="store_true")
p.add_argument("--print-info", action="store_true")
args = p.parse_args()


# functions
def organize_workspace(args):

	"""
	Last update: 22/12/2021
	Creation of folders and workspace where the script has to operate
	Verify presence of minimal set of files to work with
	"""

	if os.path.exists(args.output_dir) == False:
		os.makedirs(args.output_dir)
		sys.stderr.write(f"[{at()}] Created output directory {args.output_dir}\n")

	if args.debug:
		if os.path.exists(f"{args.output_dir}/debug") == False:
			os.makedirs(f"{args.output_dir}/debug")
			sys.stderr.write(f"[{at()}] Created debug directory {args.output_dir}/debug\n")

	return (True, args.output_dir)


def extract_heterozygous_snps(	vcf, min_af, max_af, output_dir,
								sample, het_snps_vcf, homo_snps_vcf, filter_mode):

	"""
	Last update: 16/12/2021
	Note: Read the VCF file containing SNPs and indels
	Output only heterozygous SNPs, including number of kept and removed lines
	"""

	def keep_heterozygous(Vcf_lines, filter_mode):

		"""
		Last update: 16/12/2021
		Filtering variants based on three criteria:
		- are they SNPs?
		- are they heterozygous?
		- if selected: do they PASS?
		"""

		kept, removed, homozygous, New_lines, Homo_lines = 0,0,0,[],[]

		for line in Vcf_lines:

			# split by field
			lst = line.rstrip("\b\r\n").split("\t")

			if ((filter_mode == "pass") and (lst[6] == "PASS")) or \
			(filter_mode == "all"):

				# read values
				annotations = lst[8].split(":")
				values = lst[9].split(":")
				dict = { annotations[i]:values[i] for i in range(0, len(annotations)) }

				# if it's a single heterozygous SNP
				if ((len(lst[3]) == len(lst[4]) == 1) and (dict["GT"]=="0/1")):

					# does AF fit the criteria?
					if (min_af <= float(dict["AF"]) <= max_af):

						# 4. write out lines that have fitting values
						New_lines.append(line)
						kept += 1

					# remove those without the frequency in range
					else:
						removed += 1

				# if homozygous: keep for later assignment to blocks
				elif ((len(lst[3]) == len(lst[4]) == 1) and (dict["GT"]=="0/0") \
				or (len(lst[3]) == len(lst[4]) == 1) and (dict["GT"]=="1/1")):

					Homo_lines.append(line)
					homozygous += 1

				# consider multiallelic sites
				# only if all alleles are SNPs
				# and if all alleles are not stars (spanning deletions)
				elif ((len(lst[3]) == 1) and (len(lst[4].split(",")) > 1)
				and (all([ len(x)==1 for x in lst[4].split(",") ])) \
				and (all([ x!="*" for x in lst[4].split(",") ]))):

					# this means that there are two annotations for AF
					# and that both have to be checked
					# so it is a variation on the previous block
					# which could be rendered into a function
					# assuming that there are > 1 AF annotation
					# splitting the field based on the comma
					# and converting to float the content
					AFs = [ float(x) for x in dict["AF"].split(",") ]

					# all it takes is one of the variants to be heterozygous
					# for the locus to be conserved
					# where het = AF comprised between --min-af and --max-af
					Conditions = [ float(args.min_af) <= af <= float(args.max_af) for af in AFs]
					if any(Conditions) == True:

						# 4. write out lines that have fitting values
						New_lines.append(line)
						kept += 1

					# remove those without any heterozygous snp
					# among those available
					else:
						removed += 1

				# remove homozygous SNPs
				# and indels
				else:
					removed += 1
			# exclude header lines starting with "#"
			else:
				removed += 1

		return (New_lines, Homo_lines, kept, removed, homozygous)

	# ------------------------------------

	# read SNPs
	INPUT = open(vcf, "r")
	Lines = [ line for line in INPUT ]
	INPUT.close()
	Header = [ line for line in Lines if line[0] == "#" ]
	Vcf_lines = [ line for line in Lines if line[0] != "#" ]

	# keep only heterozygous
	# if args.filter_mode == "pass", filter snps keeping only PASS
	(Vcf_lines, Homo_lines, kept, removed, homozygous) = keep_heterozygous(Vcf_lines, filter_mode)
	sys.stderr.write(f"[{at()}] Kept {kept} heterozygous SNPs ({round((kept / (kept + removed + homozygous))*100, 2)} %) out of {kept+removed+homozygous} VCF records\n")
	sys.stderr.write(f"[{at()}] Saved {homozygous} homozygous SNPs for later\n")
	sys.stderr.write(f"[{at()}] Discarded {removed} SNPs due to their uncertain nature (according to AF)\n")

	# write filtered vcf file lines to an actual vcf file output
	OUT = open(het_snps_vcf, "w")
	for line in Header:
		OUT.write(line)
	for line in Vcf_lines:
		OUT.write(line)
	OUT.close()

	# write homozygous VCF file
	OUT = open(homo_snps_vcf, "w")
	for line in Header:
		OUT.write(line)
	for line in Homo_lines:
		OUT.write(line)
	OUT.close()

	return True


def get_intervals_of_snps(snps_vcf, snp_distance):

	"""
	Last update: 22/12/2021
	Create BED regions based on the input VCF rows after their filtering
	These regions merge together SNPs as long as they are within --snp-distance
	For each, the number of variants contained in it are counted
	This function is used both with hetero and homozygous SNPs
	The output is: chr | start | end | count
	"""

	snps_vcf = BedTool(snps_vcf)
	bt_merged = snps_vcf.merge(d=snp_distance, c=1, o="count")

	return bt_merged


def count_snps_in_bed_interval(bed, vcf):

	"""
	Last update: 21/12/2021
	Note: Count how many SNPs are found inside a BED interval
	by intersecting a BED file with a VCF file
	"""

	bt_inter = bed.intersect(vcf, c=True)
	return bt_inter


def filter_by_snp_density(bt, min_num_snps):

	"""
	Filter regions based on the number of variants found in them
	Which were counted in the previous function

	v1
	Last update: 14/02/2014
	Author: Leszek Pryszcz
	Notes: Parse BED and print stats
	###
	v2
	Last update: 21/12/2021
	Author: Matteo Schiavinato
	Notes: included a return statement to fit the new code, update to python3
	"""

	out = []
	skipped = 0
	for row in bt:
		ref,start,end,count = str(row).rstrip("\n\r\b").split("\t")
		ref,start,end,count = str(ref),int(start),int(end),float(count)
		if count >= float(min_num_snps):
			out.append(row)
		else:
			skipped += 1

	new_bt = BedTool(out)

	return(new_bt, skipped)


def filter_snps(vcf, bed):

	"""
	Last update: 21/12/2021
	Remove SNPs overlapping BED regions
	"""

	vcf = BedTool(vcf)
	bed = BedTool(bed)

	filt_vcf = vcf.intersect(bed, header=True, v=True)

	return filt_vcf


def remove_overlapping_regions(bt_A, bt_B, homo_vcf):

	"""
	Last update: 22/12/2021
	Note: remove BED regions overlapping in two files
	"""

	def remove_intersection(bed_lst_A, bed_lst_B):

		"""
		Last update: 22/12/2021
		Note: remove overlapping region of the B interval from the A interval
		A intervals: homozygous blocks
		B intervals: heterozygous blocks
		"""

		Out = []

		# get coordinates
		A_chrom, A_start, A_end = bed_lst_A
		B_chrom, B_start, B_end = bed_lst_B
		A_chrom, A_start, A_end = str(A_chrom), int(A_start), int(A_end)
		B_chrom, B_start, B_end = str(B_chrom), int(B_start), int(B_end)

		# if there is no overlap
		# report bed interval as it is
		if ((B_start < 0) and (B_end < 0)):
			Out.append((A_chrom, A_start, A_end))

		# if the whole B interval is contained in A
		# which means: the whole hetero block is contained in the homo block
		# split the homo block in two
		elif ((A_start <= B_start <= A_end) and (A_start <= B_end <= A_end)):

			Out.append((A_chrom, A_start, B_start))
			Out.append((A_chrom, B_end, A_end))

		# if the whole A interval is contained in B
		# that is: the whole homo block is contained in the hetero block
		# discard the interval entirely
		elif ((B_start <= A_start <= B_end) and (B_start <= A_end <= B_end)):
			pass

		# if only beginning of B is contained in A
		# keep only from A_start to B_start
		elif ((A_start <= B_start <= A_end) and (B_end > A_end)):

			Out.append((A_chrom, A_start, B_start))

		# if only end of B is contained in A
		# keep only from B_end to A_end
		elif ((B_start < A_start) and (A_start <= B_end <= A_end)):

			Out.append((A_chrom, B_end, A_end))

		else:
			sys.stderr.write("ERROR: detected an overlap that I can't solve.\n\n")
			sys.stderr.write(str(bed_lst_A) + "\n")
			sys.stderr.write(str(bed_lst_B) + "\n")
			sys.exit()

		return Out

	# -------------------------------------------------

	# get intersection
	# with "wao", you get the two bed features adjacent in the output
	# and their overlap
	# in case of no overlap, the feature is reported as is, with an overlap of "-1"
	# you can easily remove the intersection

	# remove intersections from BED intervals of homozygous blocks
	bt_int = bt_A.intersect(bt_B, u=True)
	bt_nonint = bt_A.intersect(bt_B, v=True)
	num_intersections = len(bt_int)

	sys.stderr.write(f"[{at()}] Found {num_intersections} intersections between homo- and hetero-blocks\n")

	# operate this lengthy part only if there actually are intersections
	while (num_intersections > 0):
		bt_int = bt_int.intersect(bt_B, wo=True)
		New_intervals = []

		for row in bt_int:
			row = str(row)
			lst = row.rstrip("\b\r\n").split("\t")
			bed_lst_A = str(lst[0]), int(lst[1]), int(lst[2])
			bed_lst_B = str(lst[4]), int(lst[5]), int(lst[6])
			New_beds = remove_intersection(bed_lst_A, bed_lst_B)
			New_intervals = New_intervals + New_beds

		# merge together homo-blocks
		bt_int = BedTool(New_intervals).sort()
		bt_int = count_snps_in_bed_interval(bt_int, homo_vcf)
		num_intersections = len(bt_int.intersect(bt_B, wo=True))
		sys.stderr.write(f"[{at()}] Broken into {num_intersections} smaller intersections\n")

	# merge together intersecting and non-intersecting
	bt_int = bt_int.sort().merge()
	bt_final = bt_int.cat(bt_nonint).sort()

	# check that all have been eliminated
	num_intersections = len(bt_int.intersect(bt_B, wo=True))
	sys.stderr.write(f"[{at()}] Final number of intersections: {num_intersections}\n")

	if (num_intersections == 0):
		return bt_final
	else:
		sys.stderr.write(f"[{at()}] ERROR: could not remove all intersections. Report bug to GitHub page issues. Sorry!\n")
		sys.exit()


def get_complementary_regions(bt_A, bt_B, genome_file):

	"""
	Last update: 22/12/2021
	Run bedtools complement to obtain BED intervals
	These intervals represent the complement of the original regions
	Which in turn represented the heterozygous blocks
	Hence, the output of this function are the homozygous blocks
	"""

	bt_comp = bt_A.cat(bt_B).sort(g=genome_file).merge().complement(g=genome_file)
	return bt_comp


def add_column(bt, annot):

	"""
	Last update: 21/12/2021
	Note: Add the "annot" value as extra column to a BED file
	"""

	x = [ str(row).rstrip("\b\r\n") + "\t" + str(annot) for row in bt ]
	new_bt = BedTool(x)
	return new_bt


def combine_beds(bt_A, bt_B):

	"""
	Last update: 21/12/2021
	Note: combine two bed files into one
	"""

	x = list(bt_A)
	y = list(bt_B)
	z = x + y
	bt = BedTool(z).sort()

	return bt


def filter_by_length(bt, min_size):

	"""
	Last update: 21/12/2021
	Note: Keep only candidate LOH regions of a certain minimum size
	"""

	lst = [ str(row).rstrip("\b\r\n").split("\t") for row in bt ]
	lst = [ (str(x[0]), int(x[1]), int(x[2]), str(x[3])) for x in lst ]
	lst = [ x for x in lst if x[2]-x[1] >= min_size ]
	new_bt = BedTool(lst)
	return new_bt


def index_bam_file(input_bam):

	"""
	Last update: 20/12/2021
	Note: indexing bam file if index is not found
	"""

	# index bam file
	try:
		pysam.check_index(input_bam)

	except AttributeError:
		sys.stderr.write(f"[{at()}] BAM index not found. Indexing file...\n")
		#calculate mean cov
		if input_bam[-3:] == "bam":
			bam = input_bam
			pysam.index(bam)

		elif input_bam[-3:] == "sam":
			output_bam = f"{output_dir}/process/{sample}.{handle}.bam"
			pysam.view("-h", "-b", "-o", output_bam, input_bam, catch_stdout=False)
			bam = output_bam
			pysam.index(bam)

		else:
			sys.stderr.write(f"[{at()}] ERROR: {input_bam} does not end in \"sam\" or \"bam\". Can't determine the file type")

	return bam


def get_global_coverage(bamfile, output_dir, sample, handle):

	"""
	Last update: 20/12/2021
	Note: Get global mean coverage per position of a reference genome
	Based on the number of positions that are covered
	And the number of reads covering them
	"""

	bam = pysam.AlignmentFile(bamfile, "rb")

	Covs = {}
	for chrom in list(bam.references):
		cov_count = bam.count_coverage(chrom, quality_threshold=0, read_callback="all")
		cov_count = [ [i for i in cov_count[k] if int(i) > 0] for k in (0,1,2,3) ]
		tot_pos = sum([ len(x) for x in cov_count ])
		tot_cov = sum([ sum(x) for x in cov_count ])
		try:
			cov = float(tot_cov) / float(tot_pos)
		except ZeroDivisionError:
			cov = float(0)
		Covs[chrom] = cov

	Covs  = { chrom : Covs[chrom] for chrom in Covs.keys() if Covs[chrom] > 0 }
	global_cov = sum(Covs.values()) / len(Covs.values())

	return global_cov


def assess_coverage(input_bam, bt, meancov, args):

	"""
	v1
	Author: Leszek Pryszcz
	Notes: Report only windows with at least mincov of mean
	Last change: 14/02/2014
	###
	v2
	Author: Matteo Schiavinato
	Last change: 21/12/2021
	Notes: Now addressing ALT and REF homoblock alleles in relation to coverage
	"""


	def get_region_coverage(bed, bam, meancov):

		"""
		v1
		Author: Leszek Pryszcz
		Last update: 2014
		###
		v2
		Author: Matteo Schiavinato
		Note: Updated to python3
		Updated to new version of pysam
		Now using coverage per position instead of raw read count
		Last Update: 21/12/2021
		"""

		# unload bed coordinate
		chrom, start, end, block_type = bed.rstrip("\n\b\r").split('\t')
		start, end = int(start), int(end)
		length = end-start

		# get coverage per position
		# count_coverage() returns a tuple with 4 tuples, each one containing the coverage per position
		# of a certain base (A,C,T,G) --> (0,1,2,3) in the command below
		cov_count = bam.count_coverage(chrom, start, end, quality_threshold=0, read_callback="all")
		cov_count = [ [i for i in cov_count[k] if int(i) > 0] for k in (0,1,2,3) ]
		tot_pos = sum([ len(x) for x in cov_count ])
		tot_cov = sum([ sum(x) for x in cov_count ])
		try:
			cov = float(tot_cov) / float(tot_pos)
		except ZeroDivisionError:
			cov = float(0)

		try:
			cov_ratio = round((cov/meancov)*100, 2)
		except ZeroDivisionError:
			cov_ratio = round(float(0), 2)

		bed_line = f"{chrom}\t{start}\t{end}\t{cov_ratio}%\t{length}\t{block_type}\n"
		return bed_line

	# -------------------------------------------

	# open bam file
	bam = pysam.AlignmentFile(input_bam, "rb")
	Out = []
	total = len(bt)
	for row in bt:
		bed = str(row)
		x = get_region_coverage(bed, bam, meancov)
		Out.append(x)

	bt = BedTool(Out)
	return bt


def process_vcf_file(	args, in_vcf, output_dir, genome_file, bam, sample, handle,
						min_af, max_af, min_het_snps, snp_distance, min_size):

	"""
	Last update: 22/12/2021
	Note: Series of operations that a VCF file goes through to extract LOH blocks
	"""

	# Extract heterozygous snps from raw VCF file
	sys.stderr.write(f"[{at()}] Extracting heterozygous SNPs from VCF file...\n")
	sys.stderr.write(f"[{at()}] Considering only SNPs with {min_af} <= AF <= {max_af}...\n")
	het_snps_vcf = f"{output_dir}/{sample}.{handle}.het_snps.vcf"
	homo_snps_vcf = f"{output_dir}/{sample}.{handle}.homo_snps.vcf"

	result = extract_heterozygous_snps(	in_vcf,
										min_af,
										max_af,
										output_dir,
										sample,
										het_snps_vcf,
										homo_snps_vcf,
										args.filter_mode)

	# -------------------------------------------
	# Get heterozygous blocks with bedtools merge
	# merge bed file
	# then filter it by SNP density
	sys.stderr.write(f"[{at()}] Defining heterozygous blocks...\n")

	snps_vcf = BedTool(het_snps_vcf)
	Het_bed_blocks = get_intervals_of_snps(	snps_vcf,
							 				snp_distance)

	if args.debug:
		out = f"{output_dir}/debug/1.{handle}.het_bed_blocks.bed"
		tmp = Het_bed_blocks
		tmp.saveas(out)

	sys.stderr.write(f"[{at()}] Keeping only blocks with >= {args.min_het_snps} SNPs...\n")

	(Het_bed_blocks, skipped) = filter_by_snp_density(	Het_bed_blocks,
														args.min_het_snps)

	sys.stderr.write(f"[{at()}] {skipped} regions were removed due to insufficient SNP count\n")
	sys.stderr.write(f"[{at()}] Keeping only blocks >= {args.min_size} bp...\n")

	Het_bed_blocks = filter_by_length(	Het_bed_blocks,
										args.min_size)

	if args.debug:
		out = f"{output_dir}/debug/2.{handle}.het_bed_blocks.filt.bed"
		tmp = Het_bed_blocks
		tmp.saveas(out)

	# ------------------------------------------------------
	# get homozygous blocks
	sys.stderr.write(f"[{at()}] Defining alternative allele (ALT) homozygous blocks...\n")

	Homo_ALT_bed_blocks = get_intervals_of_snps(	homo_snps_vcf,
								 					snp_distance)

	if args.debug:
		out = f"{output_dir}/debug/3.{handle}.homo_bed_blocks.ALT.bed"
		tmp = Homo_ALT_bed_blocks
		tmp.saveas(out)

	sys.stderr.write(f"[{at()}] Keeping only blocks with >= {args.min_het_snps} SNPs...\n")

	(Homo_ALT_bed_blocks, skipped) = filter_by_snp_density(	Homo_ALT_bed_blocks,
															args.min_het_snps)

	sys.stderr.write(f"[{at()}] {skipped} regions were removed due to insufficient SNP count\n")

	Homo_ALT_bed_blocks = filter_by_length(	Homo_ALT_bed_blocks,
											args.min_size)

	if args.debug:
		out = f"{output_dir}/debug/4.{handle}.homo_bed_blocks.ALT.filt.bed"
		tmp = Homo_ALT_bed_blocks
		tmp.saveas(out)

	# ------------------------------------------------------
	# remove homo ALT block if overlapping a hetero block
	# it could be that there are hetero- and homo-zygous SNPs
	# interleaved between each other
	# these must not be considered blocks
	sys.stderr.write(f"[{at()}] Adjusting ALT homozygous blocks to not overlap heterozygous blocks...\n")

	Homo_ALT_bed_blocks = remove_overlapping_regions(Homo_ALT_bed_blocks,
													Het_bed_blocks,
													homo_snps_vcf)

	if args.debug:
		out = f"{output_dir}/debug/5.{handle}.homo_bed_blocks.ALT.filt.no_overlap.bed"
		tmp = Homo_ALT_bed_blocks
		tmp.saveas(out)

	sys.stderr.write(f"[{at()}] Left with {len(Homo_ALT_bed_blocks)} homo-blocks after intersecting with hetero-blocks\n")

	# ------------------------------------------------------
	# Obtaining complementary regions to heterozygous blocks
	# get complementary bed file
	sys.stderr.write(f"[{at()}] Getting homozygous regions (i.e. candidate LOH blocks)...\n")
	homo_REF_bed = f"{output_dir}/process/{sample}.{handle}.d{snp_distance}bp.homo_REF.bed"

	Homo_REF_bed_blocks = get_complementary_regions(Het_bed_blocks,
													Homo_ALT_bed_blocks,
													genome_file)

	if args.debug:
		out = f"{output_dir}/debug/6.{handle}.homo_bed_blocks.REF.bed"
		tmp = Homo_REF_bed_blocks
		tmp.saveas(out)

	# ------------------------------------------------------
	# remove homo REF block if overlapping a hetero block
	# it could be that there are hetero- and homo-zygous SNPs
	# interleaved between each other
	# these must not be considered blocks
	sys.stderr.write(f"[{at()}] Adjusting REF homozygous blocks to not overlap heterozygous blocks...\n")

	bt_homo = BedTool(homo_snps_vcf)
	Homo_REF_bed_blocks = count_snps_in_bed_interval(Homo_REF_bed_blocks,
													bt_homo)
	Homo_REF_bed_blocks = filter_by_length(	Homo_REF_bed_blocks,
											args.min_size)
	Homo_REF_bed_blocks = remove_overlapping_regions(Homo_REF_bed_blocks,
													Het_bed_blocks,
													homo_snps_vcf)

	if args.debug:
		out = f"{output_dir}/debug/7.{handle}.homo_bed_blocks.REF.no_overlap.bed"
		tmp = Homo_REF_bed_blocks
		tmp.saveas(out)

	sys.stderr.write(f"[{at()}] Left with {len(Homo_REF_bed_blocks)} homo-blocks after intersecting with hetero-blocks\n")

	# --------------------------------------------------
	# add REF or ALT annotation
	# and then combine REF and ALT homozygous blocks
	# and then filter by length
	sys.stderr.write(f"[{at()}] Combining {len(Homo_REF_bed_blocks)} REF and {len(Homo_ALT_bed_blocks)} ALT blocks into a single BED file...\n")
	Homo_REF = add_column(Homo_REF_bed_blocks, "REF")
	Homo_ALT = add_column(Homo_ALT_bed_blocks, "ALT")
	Homo_blocks = combine_beds(	Homo_REF, Homo_ALT)
	total = len(Homo_blocks)

	if args.debug:
		out = f"{output_dir}/debug/8.{handle}.homo_bed_blocks.REF_and_ALT.bed"
		tmp = Homo_blocks
		tmp.saveas(out)

	sys.stderr.write(f"[{at()}] Now working with {total} REF & ALT blocks\n")

	Homo_blocks = filter_by_length(Homo_blocks, args.min_size)
	filtered = len(Homo_blocks)
	discarded = total - filtered

	if args.debug:
		out = f"{output_dir}/debug/9.{handle}.homo_bed_blocks.REF_and_ALT.filt.bed"
		tmp = Homo_blocks
		tmp.saveas(out)

	sys.stderr.write(f"[{at()}] {discarded} blocks were discarded because shorter than {args.min_size} bp\n")

	# -----------------------------------------
	# filter by real coverage from the BAM file

	# get mean global coverage
	indexed_bam = index_bam_file(bam)
	meancov = get_global_coverage(indexed_bam, output_dir, sample, handle)

	sys.stderr.write(f"[{at()}] Mean coverage: {round(meancov, 2)}x\n")

	LOH = assess_coverage(	indexed_bam,
							Homo_blocks,
							meancov,
							args)

	sys.stderr.write(f"[{at()}] Computed coverage for selected LOH blocks\n")

	if args.debug:
		out = f"{output_dir}/debug/10.{handle}.LOH_candidates.bed"
		tmp = LOH
		tmp.saveas(out)

	return (LOH, homo_snps_vcf, het_snps_vcf)


def use_intersection_intervals(Out, filter_type):

	"""
	Last update: 21/12/2021
	Intersect t0 and t1000 VCF files
	"""

	# take heterozygous VCF files
	t1000_bed = Out["exp"][0]
	t0_bed = Out["t0"][0]

	# intersect files
	bt_A = BedTool(t1000_bed)
	bt_B = BedTool(t0_bed)

	if filter_type == "remove":
		bt_inter = bt_A.intersect(bt_B, v=True)
	elif filter_type == "keep":
		bt_inter = bt_A.intersect(bt_B, u=True)

	return bt_inter


def main():

	"""
	Last update: 22/12/2021
	Note: Function carrying on the main operations
	"""

	# if required print script info and quit
	if args.print_info:
		print(script_info)
		sys.exit(0)

	# create output directory if not existing
	sys.stderr.write(f"[{at()}] Preparing workspace...\n")
	(result, output_dir) = organize_workspace(args)

	# iterate over all provided Vcfs
	if args.t0_vcf:
		Vcfs = { args.vcf : "exp", args.t0_vcf : "t0" }
		Bams = { args.vcf : args.bam, args.t0_vcf : args.t0_bam }
	else:
		Vcfs = { args.vcf : "exp"}
		Bams = { args.vcf : args.bam}

	Out = { handle : "" for handle in Vcfs.keys() }

	for in_vcf in Vcfs.keys():

		sys.stderr.write(f"[{at()}] Working on: {in_vcf}\n")

		handle = Vcfs[in_vcf]
		bam = Bams[in_vcf]

		(LOH, homo_snps, hetero_snps) = process_vcf_file(
										args, in_vcf, args.output_dir, args.genome_file,
										bam, args.sample, handle,
										args.min_af, args.max_af, args.min_het_snps,
										args.snp_distance, args.min_size)

		Out[handle] = [LOH, homo_snps, hetero_snps]
		out = f"{output_dir}/{args.sample}.{handle}.LOH_candidates.tsv"
		LOH.saveas(out)

	# if t0 is provided, remove LOH blocks found in t0 from those found in t1000
	# these are the background noise of pre-existing LOH blocks
	# that are found at both t0 and t1000
	# we're interested only in those found at t1000 which have evolved after t0
	if args.t0_vcf:
		sys.stderr.write(f"[{at()}] Handling blocks found in \"t0\" with mode: \"{args.t0_filter_type}\"\n")
		LOH_filt = use_intersection_intervals(Out, args.t0_filter_type)
	else:
		LOH_filt = Out["exp"][0]

	if args.debug:
		out = f"{output_dir}/debug/11.exp.LOH_blocks.bed"
		tmp = LOH_filt
		tmp.saveas(out)

	# count SNPs in selected blocks
	# counting heterozygous
	# and then counting homozygous
	bt_homo = BedTool(Out["exp"][1])
	bt_hetero = BedTool(Out["exp"][2])
	LOH_w_snps = count_snps_in_bed_interval(LOH_filt, bt_homo)
	LOH_w_snps = count_snps_in_bed_interval(LOH_w_snps, bt_hetero)

	# write to output
	# including a header
	out = f"{output_dir}/{args.sample}.LOH_blocks.tsv"
	OUTPUT = open(out, "w")
	OUTPUT.write("\t".join(["#Chrom", "Start", "End", "Cov", "Length", "Allele", "Homo_snps", "Hetero_snps"]) + "\n")
	for row in LOH_w_snps:
		OUTPUT.write(str(row))
	OUTPUT.close()

	sys.stderr.write(f"[{at()}] Done!\n")

# run the script
if __name__=='__main__':
  main()
