#!/usr/bin/env python3

# version and info
script_info = """
###
Author: Matteo Schiavinato
Based on the work of: Leszek Pryszcz (2014) and Veronica Mixao (2018)
Last change: 14/12/2021
###
"""

# import modules
import argparse as ap
import os
import sys
import pysam
import subprocess
from time import asctime as at
import pybedtools
from pybedtools import BedTool

# help section
if len(sys.argv) == 1:
	sys.argv.append("--help")

if (sys.argv[1] in ["--help", "-h", "-help", "help", "getopt", "usage"]):
	sys.stderr.write("""

J LOH
Still the one from the block
-
Extact LOH blocks from SNPs and a reference genome
-
v 0.3.1
--------------------------------------------------------------------------------
by Matteo Schiavinato
largely based on:
Pryszcz et al., 2014	https://doi.org/10.1093/gbe/evu082
Mixao et al., 2019		https://doi.org/10.3389/fgene.2019.00383
--------------------------------------------------------------------------------

Usage:
./jloh --vcf <VCF> --genome-file <GENOME_FILE> --bam <BAM> [options]

[mandatory]
--vcf               Input VCF file containing all types of variants             [!]
--genome-file       File with chromosome lengths (chromosome <TAB> size)        [!]
--bam               BAM file used to call the --vcf variants                    [!]

[optional]
--sample            Sample name / Strain name for output files                  [loh_blocks]
--output-dir        Output directory                                            [loh_blocks_out]
--t0-vcf            VCF with variants to ignore from --vcf                      [off]
--t0-bam            BAM file used to call the --t0-vcf variants                 [off]
--t0-filter-type    What to do with t0 LOH events? "keep" or "remove"           [remove]
--min-het-snps      Min. num. of heterozygous SNPs in heterozygous region       [2]
--snp-distance      Min. distance (bp between SNPs for blocks definition        [100]
--min-size          Min. LOH block size                                         [100]
--block-lengths     Comma-sep. list of desired distances between LOH blocks     [100,1000,5000]
--min-af            Min. allele frequency to consider a variant heterozygous    [0.3]
--max-af            Max. allele frequency to consider a variant heterozygous    [0.7]
--min-frac-cov      Min. mean coverage fraction for LOH blocks                  [0.75]
                    (used only if --bam specified)
--max-frac-cov      Max. mean coverage fraction for LOH blocks                  [1.25]
                    (used only if --bam specified)
--print-info        Show authors and edits with dates                           [off]

""")
	sys.exit(0)

# argument parser
p = ap.ArgumentParser(description="")
p.add_argument("--vcf", type=str)
p.add_argument("--genome-file")
p.add_argument("--sample", default="loh_blocks")
p.add_argument("--output-dir", default="loh_blocks_out")
p.add_argument("--t0-vcf", type=str, default=None)
p.add_argument("--t0-bam", type=str, default=None)
p.add_argument("--t0-filter-type", choices=["keep", "remove"], default="remove")
p.add_argument("--min-het-snps", type=float, default=2)
p.add_argument("--snp-distance", default=100, type=int)
p.add_argument("--min-size", default=100, type=int)
p.add_argument("--block-lengths", default="100,1000,5000", type=str)
p.add_argument("--min-af", default=0.3, type=float)
p.add_argument("--max-af", default=0.7, type=float)
p.add_argument("--bam", type=str)
p.add_argument("--min-frac-cov", type=float, default=0.75)
p.add_argument("--max-frac-cov", type=float, default=1.25)
p.add_argument("--print-info", action="store_true")
args = p.parse_args()


# functions
def organize_workspace(output_dir, min_frac_cov, max_frac_cov, bam):

	"""
	Creation of folders and workspace where the script has to operate
	Verify presence of minimal set of files to work with
	"""

	if os.path.exists(output_dir) == False:
		os.makedirs(output_dir)
		sys.stderr.write(f"[{at()}] Created output directory {output_dir}\n")

	if os.path.exists(f"{output_dir}/process") == False:
		os.mkdir(f"{output_dir}/process")

	# check if bam is used or not
	if bam and not (min_frac_cov or max_frac_cov):
		sys.stderr.write(f"[{at()}] ERROR: If you specify a --bam file you may want to use --min-frac-cov or --max-frac-cov\n")
		sys.exit()

	if (min_frac_cov or max_frac_cov) and not bam:
		sys.stderr.write(f"[{at()}] ERROR: If you use --min-frac-cov or --max-frac-cov you may want to specify a --bam file\n")
		sys.exit()

	return (True, output_dir)



def extract_heterozygous_snps(vcf, min_af, max_af, output_dir, sample, het_snps_vcf):

	"""
	v2
	Author: Matteo Schiavinato
	Last change: 14/12/2021
	Note: Read the VCF file containing SNPs and indels
	Output only heterozygous SNPs, including number of kept and removed lines
	"""

	def extract_header_line(line):
		if line[0] == "#":
			return line
		else:
			return False

	def extract_heterozygous_line(line):

		if line[0] != "#":

			# split by field
			lst = line.rstrip("\b\r\n").split("\t")

			# read values
			annotations = lst[8].split(":")
			values = lst[9].split(":")
			dict = { annotations[i]:values[i] for i in range(0, len(annotations)) }

			# if it's a single heterozygous SNP
			if ((len(lst[3]) == len(lst[4]) == 1) and (dict["GT"]=="0/1")):

				# does AF fit the criteria?
				if (min_af <= float(dict["AF"]) <= max_af):

					# 4. write out lines that have fitting values
					return line

				# remove those without the frequency in range
				else:
					return False

			# consider multiallelic sites
			elif ((len(lst[3]) == 1) and (len(lst[4].split(",")) > 1)):

				# this means that there are two annotations for AF
				# and that both have to be checked
				# so it is a variation on the previous block
				# which could be rendered into a function
				# assuming that there are > 1 AF annotation
				# splitting the field based on the comma
				# and converting to float the content
				AFs = [ float(x) for x in dict["AF"].split(",") ]

				# all it takes is one of the variants to be heterozygous
				# for the locus to be conserved
				# where het = AF comprised between --min-af and --max-af
				Conditions = [ float(args.min_af) <= af <= float(args.max_af) for af in AFs]
				if any(Conditions) == True:

					# 4. write out lines that have fitting values
					return line

				# remove those without any heterozygous snp
				# among those available
				else:
					return False

			# remove homozygous SNPs
			# and indels
			else:
				return False
		# exclude header lines starting with "#"
		else:
			return False

	# read header
	INPUT = open(vcf, "r")
	New_lines_header = [ extract_header_line(line) for line in INPUT ]
	New_lines_header = [ i for i in New_lines_header if i != False ]
	INPUT.close()

	# read heterozygous lines
	INPUT = open(vcf, "r")
	New_lines_vcf = [ extract_heterozygous_line(line) for line in INPUT ]
	removed = len([i for i in New_lines_vcf if i == False])
	New_lines_vcf = [ i for i in New_lines_vcf if i != False ]
	kept = len(New_lines_vcf)
	INPUT.close()

	# merge
	New_lines = New_lines_header + New_lines_vcf

	sys.stderr.write(f"[{at()}] Kept {kept} heterozygous SNPs ({round((kept / (kept + removed))*100, 2)} %) out of {kept+removed} VCF records\n")

	# write filtered bed file lines to an actual bed file output
	OUT = open(het_snps_vcf, "w")
	for line in New_lines:
		OUT.write(line)
	OUT.close()

	return (True, het_snps_vcf)


def merge_bed_intervals(sample, output_dir, snp_distance, het_snps_vcf, bed_out):

	"""
	Create BED regions based on the input VCF rows after their filtering
	These regions are --snp-distance large and centered on the SNPs
	For each snp_distance, the number of variants contained in it are counted
	The output is: chr | start | end | count
	"""

	bt = BedTool(het_snps_vcf)
	bt_merged = bt.merge(d=100, c=1, o="count")
	bt_merged.saveas(bed_out)

	return (True, snp_distance)


def add_length(bed, output_bed):

	"""
	Compute length of BED interval and add it as 5th column
	"""

	INPUT = open(bed, "r")
	Lines = [line.rstrip("\b\r\n").split("\t") for line in INPUT]
	INPUT.close()

	OUTPUT = open(output_bed, "w")
	for lst in Lines:
		chrom, start, end, count = lst
		length = int(end)-int(start)
		OUTPUT.write("\t".join([chrom, start, end, count, str(length)]) + "\n")

	OUTPUT.close()

	return True

def filter_by_snp_density(in_bed, out_bed, output_dir, sample, snp_distance, minC, maxC, minL):

	"""
	Filter regions based on the number of variants found in them
	Which were counted in the previous function

	v1
	Author: Leszek Pryszcz
	Notes: Parse BED and print stats
	Last change: 14/02/2014
	###
	v2
	Author: Matteo Schiavinato
	Notes: included a return statement to fit the new code, update to python3
	Last change: 26/11/2021
	"""

	handle = open(in_bed, "r")

	out = []
	i, skipped = 0, 0
	for l in handle:
		i += 1
		c = 0
		ref,start,end,count,length = l.split()
		ref,start,end,count,length = str(ref),int(start),int(end),float(count),int(length)
		if minC <= count <= maxC and length >= minL:
			out.append(l)
		else:
			skipped += 1

	# write filtered bed file lines to an actual bed file output
	OUT = open(out_bed, "w")
	for line in out:
		OUT.write(line)
	OUT.close()

	return (True, minC, maxC, minL)


def get_complementary_regions(complement_bed, filt_bed, genome_file):

	"""
	Run bedtools complement to obtain BED intervals
	These intervals represent the complement of the original regions
	Which in turn represented the heterozygous blocks
	Hence, the output of this function are the homozygous blocks
	"""

	bt = BedTool(filt_bed)
	bt_comp = bt.complement(g=genome_file)
	bt_comp.saveas(complement_bed)

	return True


def filter_by_length(in_bed, out_bed, min_size):

	"""
	Keep only candidate LOH regions of a certain minimum size
	"""

	INPUT = open(in_bed, "r")
	OUTPUT = open(out_bed, "w")

	for line in INPUT:
		chr,start,end = line.rstrip("\n\r\b").split("\t")
		length = int(end) - int(start)
		out_lst = [str(i) for i in [chr,start,end,length]]
		OUTPUT.write("\t".join(out_lst) + "\n")

	INPUT.close()
	OUTPUT.close()

	return True


def filter_by_coverage(bam_file, bed_file, covfr, cmax):

	"""
	v1
	Author: Leszek Pryszcz
	Notes: Report only windows with at least mincov of mean
	Last change: 14/02/2014
	###
	v2
	Author: Matteo Schiavinato
	Notes: update to python3
	Last change: 26/11/2021
	###
	v3
	Author: Matteo Schiavinato
	Notes: Minor syntax adjustments
	Last change: 14/12/2021
	"""

	def check_region_coverage(bed, sam, covfr, meancov, cmax):

		#unload bed coordinate
		chrom, start, end, length = bed.rstrip("\n\b\r").split('\t')
		start, end = int(start), int(end)
		#get read count within range of bed file
		c = sam.count(chrom, start, end)
		#check if correct coverage
		cov = c *1.0 / (end-start)
		if cov < float(covfr) * meancov or cov > float(cmax) * meancov:
			cov = round(cov, 2)
			bed_line = f"{chrom}\t{start}\t{end}\t{cov}\t{length}\n"
			return bed_line
		else:
			return False

	# open bed file
	bedstream = open(bed_file, "r")

	#calculate mean cov
	if bam_file[-3:] == "bam":
		sam = pysam.AlignmentFile(bam_file, "rb")
	elif bam_file[-3:] == "sam":
		sam = pysam.AlignmentFile(bam_file, "r")
	else:
		sys.stderr.write(f"ERROR: {bam_file} does not end in \"sam\" or \"bam\". Can't determine the file type")

	# this has to be fixed
	# veronica computes the genome size from the sam file
	# this is not correct because the sam file could contain only a subset
	# hence, we must compute the number of covered positions only
	# and divide the number of reads by that
	# must be fixed in next version
	meancov = 1.0 * sam.mapped / sum(sam.lengths)
	sys.stderr.write(f"[{at()}] Mean coverage: {round(meancov, 2)}x\n")

	#select windows
	Out = [ check_region_coverage(bed, sam, covfr, meancov, cmax) for bed in bedstream ]
	removed = len([ i for i in Out if i == False ])
	Out = [ i for i in Out if i != False ]
	kept = len(Out)

	sys.stderr.write(f"[{at()}] Kept {kept} candidate LOH regions based on their coverage ({round((kept / (kept + removed))*100, 2)} %) out of {kept+removed} regions\n")

	return Out


def process_vcf_file(	in_vcf, output_dir, genome_file, bam, sample, handle,
						min_af, max_af, min_het_snps, snp_distance,
						min_frac_cov, max_frac_cov, min_size):

	"""
	v1
	Series of operations that a VCF file goes through to extract LOH blocks
	Last edit: 14/12/2021
	"""

	# Extract heterozygous snps from raw VCF file
	sys.stderr.write(f"[{at()}] Extracting heterozygous SNPs from VCF file...\n")
	sys.stderr.write(f"[{at()}] Considering only SNPs with {min_af} <= AF <= {max_af}...\n")
	het_snps_vcf = f"{output_dir}/{sample}.{handle}.het_snps.vcf"

	(result, het_snps_vcf) = extract_heterozygous_snps(	in_vcf,
														min_af,
														max_af,
														output_dir,
														sample,
														het_snps_vcf)

	# -------------------------------------------extract_heterozygous_snps
	# Get heterozygous blocks with bedtools merge
	# merge bed file
	sys.stderr.write(f"[{at()}] Defining heterozygous blocks for {sample}...\n")
	merged_bed_out = f"{output_dir}/process/{sample}.{handle}.d{snp_distance}bp_provisory.bed"

	(result, snp_distance) = merge_bed_intervals(sample,
												 output_dir,
												 snp_distance,
												 het_snps_vcf,
												 merged_bed_out)

	# add length to BED file
	sys.stderr.write(f"[{at()}] Calculating length of BED intervals...\n")
	bed_with_length = f"{output_dir}/process/{sample}.{handle}.d{snp_distance}bp_provisory_w_len.bed"

	result = add_length(merged_bed_out, bed_with_length)

	# ---------------------------------------------
	# run filtering function on the merged bed file
	sys.stderr.write(f"[{at()}] Keeping only blocks with > 1 SNP...\n")
	minC, maxC, minL = float(min_het_snps), float("inf"), float(0)
	filt_bed = f"{output_dir}/process/{sample}.{handle}.d{snp_distance}bp.bed"

	(result, minC, maxC, minL) = filter_by_snp_density(	bed_with_length,
														filt_bed,
														output_dir,
														sample,
														snp_distance,
														minC,
														maxC,
														minL)

	# ------------------------------------------------------
	# Obtaining complementary regions to heterozygous blocks
	# get complementary bed file
	sys.stderr.write(f"[{at()}] Getting complementary regions...\n")
	complement_bed = f"{output_dir}/process/{sample}.{handle}.d{snp_distance}bp.complement.bed"

	result = get_complementary_regions(	complement_bed,
										filt_bed,
										genome_file)

	# --------------------------------------------------
	# Filter the complement to get the homozygous blocks
	sys.stderr.write(f"[{at()}] Getting candidate LOH blocks...\n")
	filt_compl_bed = f"{output_dir}/process/{sample}.{handle}.homo.d{snp_distance}bp.bed"

	result = filter_by_length(complement_bed,
							  filt_compl_bed,
							  min_size)

	# -----------------------------------------
	# filter by real coverage from the BAM file
	# index bam file
	if os.path.exists(f"{bam}.bai") == False:
		sys.stderr.write(f"[{at()}] BAM index not found. Indexing BAM file...\n")
		pysam.index(bam)

	# use the filtered bed file as input for next step
	Final_bed_lines = filter_by_coverage(	bam,
											filt_compl_bed,
											min_frac_cov,
											max_frac_cov)

	final_bed_file = f"{output_dir}/process/{sample}.{handle}.LOH_blocks.bed"

	# write final bed file lines to an actual bed file output
	OUT = open(final_bed_file, "w")
	for line in Final_bed_lines:
		OUT.write(line)
	OUT.close()

	return (True, final_bed_file)


def remove_intersection_intervals(Out, unique_t1000_bed):

	"""
	v1
	Intersect t0 and t1000 VCF files
	Keep only LOH events found in t1000 but not in t0
	Last edit: 13/12/2021
	"""

	t1000_bed = Out["exp"]
	t0_bed = Out["t0"]

	bt_A = BedTool(t1000_bed)
	bt_B = BedTool(t0_bed)
	bt_inter = bt_A.intersect(bt_B, v=True)
	bt_inter.saveas(unique_t1000_bed)

	return (True, unique_t1000_bed)


def keep_intersection_intervals(Out, unique_t1000_bed):

	"""
	v1
	Intersect t0 and t1000 VCF files
	Keep only LOH events found in both t1000 and t0
	Last edit: 13/12/2021
	"""

	t1000_bed = Out["exp"]
	t0_bed = Out["t0"]

	bt_A = BedTool(t1000_bed)
	bt_B = BedTool(t0_bed)
	bt_inter = bt_A.intersect(bt_B, u=True)
	bt_inter.saveas(unique_t1000_bed)

	return (True, unique_t1000_bed)


def main():

	"""
	Function carrying on the main operations
	"""

	# --------------------------------------
	# if required print script info and quit
	if args.print_info:
		print(script_info)
		sys.exit(0)

	# ---------------------------------------
	# create output directory if not existing
	sys.stderr.write(f"[{at()}] Preparing workspace...\n")
	(result, output_dir) = organize_workspace(	args.output_dir,
												args.min_frac_cov,
												args.max_frac_cov,
												args.bam)

	# iterate over all provided Vcfs
	if args.t0_vcf:
		Vcfs = { args.vcf : "exp", args.t0_vcf : "t0" }
		Bams = { args.vcf : args.bam, args.t0_vcf : args.t0_bam }
	else:
		Vcfs = { args.vcf : "exp"}
		Bams = { args.vcf : args.bam}

	Out = { handle : "" for handle in Vcfs.keys() }

	for in_vcf in Vcfs.keys():

		sys.stderr.write(f"[{at()}] Working on: {in_vcf}\n")

		handle = Vcfs[in_vcf]
		bam = Bams[in_vcf]

		(result, out_vcf) = process_vcf_file(
							in_vcf, args.output_dir, args.genome_file,
							bam, args.sample, handle,
							args.min_af, args.max_af, args.min_het_snps, args.snp_distance,
							args.min_frac_cov, args.max_frac_cov, args.min_size)

		Out[handle] = out_vcf

	# if t0 is provided, remove LOH blocks found in t0 from those found in t1000
	# these are the background noise of pre-existing LOH blocks
	# that are found at both t0 and t1000
	# we're interested only in those found at t1000 which have evolved after t0
	unique_t1000_bed = f"{output_dir}/{args.sample}.LOH_blocks.filt.bed"

	if args.t0_vcf:

		sys.stderr.write(f"[{at()}] Handling blocks found in \"t0\" with mode: \"{args.t0_filter_type}\"\n")

		if args.t0_filter_type == "remove":
			(result, output_loh_bed) = remove_intersection_intervals(Out, unique_t1000_bed)

		elif args.t0_filter_type == "keep":
			(result, output_loh_bed) = keep_intersection_intervals(Out, unique_t1000_bed)

		else:
			sys.stderr.write(f"[{at()}] ERROR: the --t0-filter-type option had a strange specification: \"{args.t0_filter_type}\". Only \"keep\" or \"remove\" can be specified.\n")
			sys.exit()

	# if no t0, just copy the previous output file
	else:
		output_loh_bed = Out["exp"]
		cmd_copy = f"cp {output_loh_bed} {unique_t1000_bed}"
		subprocess.run([cmd_copy], check=True, shell=True)

	sys.stderr.write(f"[{at()}] Done!\n")

# run the script
if __name__=='__main__':
  main()
