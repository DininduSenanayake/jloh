#!/usr/bin/env python3

"""
###
JLOH - Inferring Loss of Heterozygosity Blocks from Short-read sequencing data

Copyright (C) 2023 Matteo Schiavinato

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program.  If not, see <https://www.gnu.org/licenses/>.
###
"""



import argparse as ap
import sys
import pandas as pd
import multiprocessing as mp
from time import asctime as at
from operator import itemgetter

# help section
if len(sys.argv) == 1:
    sys.argv.append("--help")

if (sys.argv[1] in ["--help", "-h", "-help", "help", "getopt", "usage"]):
    sys.stderr.write("""

Calculate heterozygous and homozygous SNP density distributions from a VCF file

Usage:
jloh stats --vcf <VCF>

[I/O]

--vcf               Input VCF file to use for density calculations              [!]

[parameters]

--threads           Number of max. parallel operations                          [4]
--window-size       Size in bp to use for distribution                          [1000]
--step-size         Step size in bp for sliding window                          [500]

""")
    sys.exit(0)


p = ap.ArgumentParser()
p.add_argument("--vcf")
p.add_argument("--threads", default=4, type=int)
p.add_argument("--window-size", default=1000, type=int)
p.add_argument("--step-size", default=500, type=int)
args = p.parse_args()


# functions

def hetero_and_homo_snps(vcf):

    """
    Last update: 03/03/2022
    """

    # read SNPs
    INPUT = open(vcf, "r")
    Vcf_lines = [ line for line in INPUT if line[0] != "#" ]
    INPUT.close()

    Het_lines, Homo_lines = [],[]

    for line in Vcf_lines:

        # split by field
        lst = line.rstrip("\b\r\n").split("\t")

        # read values
        annotations = lst[8].split(":")
        values = lst[9].split(":")
        dict = { annotations[i]:values[i] for i in range(0, len(annotations)) }

        # if it's a single heterozygous SNP
        if ((len(lst[3]) == len(lst[4]) == 1) and (dict["GT"]=="0/1")):

            # 4. write out lines that have fitting values
            Het_lines.append(line)

        # if homozygous: keep for later assignment to blocks
        elif ((len(lst[3]) == len(lst[4]) == 1) and (dict["GT"]=="0/0") \
        or (len(lst[3]) == len(lst[4]) == 1) and (dict["GT"]=="1/1")):

            Homo_lines.append(line)

        # consider multiallelic sites
        # only if all alleles are SNPs
        # and if all alleles are not stars (spanning deletions)
        elif ((len(lst[3]) == 1) and (len(lst[4].split(",")) > 1)
        and (all([ len(x)==1 for x in lst[4].split(",") ])) \
        and (all([ x!="*" for x in lst[4].split(",") ]))):

            # this means that there are two annotations for AF
            # and that both have to be checked
            # so it is a variation on the previous block
            # which could be rendered into a function
            # assuming that there are > 1 AF annotation
            # splitting the field based on the comma
            # and converting to float the content
            AFs = [ float(x) for x in dict["AF"].split(",") ]

            # all it takes is one of the variants to be heterozygous
            # for the locus to be conserved
            # where het = AF comprised between --min-af and --max-af
            # 4. write out lines that have fitting values
            Het_lines.append(line)

    return Het_lines, Homo_lines


def get_chrom_lengths_from_vcf(vcf):

    """
    12/08/2022
    """

    IN = open(args.vcf, "r")
    Header = [line.rstrip("\r\b\n") for line in IN if line[0] == "#"]
    IN.close()

    Ctg_lines = [x.replace("##contig=<", "").replace(">", "") for x in Header if "##contig" in x]
    Ctg_lines = [x.split(",") for x in Ctg_lines]

    Chrom_lengths = {x[0].split("=")[1] : int(x[1].split("=")[1]) for x in Ctg_lines}
    return Chrom_lengths


def is_a_snp(line):

    """
    Last update: 03/03/2022
    """

    lst = line.rstrip("\r\b\n").split("\t")
    ref, alt = lst[3].split(","), lst[4].split(",")
    if (all([len(x)==1 for x in ref]) and all([len(y)==1 for y in alt])) == True:
        return True
    else:
        return False


def count_snps_in_window(Snps, w_start, w_end):

    """
    23/08/2022
    """

    tot = 0
    k = 0

    if len(Snps) > 0:
        while (k < len(Snps)):
            if (Snps[k] >= w_start) and (Snps[k] <= w_end):
                tot+=1
            if (Snps[k] > w_end):
                break
            k += 1
    else:
        tot = 0

    return tot


def get_chrom_snps(args, chrom_snps, chrom_len, chrom, queue):

    """
    Last update: 03/11/2022
    """

    w_start = 0
    w_end = w_start + args.window_size
    while w_end < chrom_len:
        w_snps = count_snps_in_window(chrom_snps, w_start, w_end)
        w_start += args.step_size
        w_end += args.step_size
        queue.put([chrom, w_start, w_snps])


def get_chrom_distances(chrom_snps, chrom, queue):

    """
    Last update: 23/08/2022
    """

    for snp in chrom_snps:
        idx = chrom_snps.index(snp)
        if idx > 0:
            d = chrom_snps[idx] - chrom_snps[idx-1]
            queue.put(d)


def calculate_chrom_snp_densities(Variants, Chrom_lengths, args):

    """
    Last update: 03/11/2022
    """

    # extract SNPs and chromosome lengths
    # subdivide SNPs by chromosome
    Snps = [ (line.split("\t")[0], line) for line in Variants if is_a_snp(line) == True ]
    Snps_by_chrom = { chrom : [] for chrom in Chrom_lengths.keys() }
    Distances = []

    for snp in Snps:
        Snps_by_chrom[snp[0]].append(int(snp[1].split("\t")[1]))

    queue = mp.Manager().Queue()
    pool = mp.Pool(args.threads)

    for chrom in Snps_by_chrom.keys():
        pool.apply_async(get_chrom_snps, args=(args, Snps_by_chrom[chrom], Chrom_lengths[chrom], chrom, queue))

    pool.close()
    pool.join()

    out = []
    while queue.qsize() > 0:
        x = queue.get()
        out.append(x)

    df = pd.DataFrame(out)
    df.columns = ["Chrom", "W_start", "Snps"]
    df = df.sort_values(by=["Chrom", "W_start"], ascending=[True, True])

    df = df.loc[df["Snps"] > 0, :]
    df_quant = df.quantile(q=[0.05, 0.10, 0.15, 0.50, 0.85, 0.90, 0.95])

    return (df, df_quant)


def main(args):

    # split
    sys.stderr.write(f"[{at()}] Reading SNPs\n")
    Hetero_lines, Homo_lines = hetero_and_homo_snps(args.vcf)
    sys.stderr.write(f"[{at()}] found {len(Hetero_lines)} het SNPs and {len(Homo_lines)} homo SNPs\n")

    sys.stderr.write(f"[{at()}] Reading chrom lengths from VCF header\n")
    Chrom_lengths = get_chrom_lengths_from_vcf(args.vcf)
    sys.stderr.write(f"[{at()}] Read {len(Chrom_lengths.keys())} chromosome names and their lengths\n")
    All = Hetero_lines + Homo_lines

    # get densities
    sys.stderr.write(f"[{at()}] Calculating heterozygous SNP densities\n")
    Het, Het_quant = calculate_chrom_snp_densities(Hetero_lines, Chrom_lengths, args)
    sys.stderr.write(f"[{at()}] Calculating homozygous SNP densities\n")
    Homo, Homo_quant = calculate_chrom_snp_densities(Homo_lines, Chrom_lengths, args)
    sys.stderr.write(f"[{at()}] Combining to get general SNP densities\n")
    All, All_quant = calculate_chrom_snp_densities(All, Chrom_lengths, args)

    if All.empty:
        all_median = float(0)
        all_mean = float(0)
        all_min = float(0)
        all_max = float(0)
    else:
        all_median = round(All["Snps"].median(), 1)
        all_mean = round(All["Snps"].mean(), 1)
        all_min = round(All["Snps"].min(), 1)
        all_max = round(All["Snps"].max(), 1)

    if Het.empty:
        het_median = float(0)
        het_mean = float(0)
        het_min = float(0)
        het_max = float(0)
    else:
        het_median = round(Het["Snps"].median(), 1)
        het_mean = round(Het["Snps"].mean(), 1)
        het_min = round(Het["Snps"].min(), 1)
        het_max = round(Het["Snps"].max(), 1)

    if Homo.empty:
        homo_median = float(0)
        homo_mean = float(0)
        homo_min = float(0)
        homo_max = float(0)
    else:
        homo_median = round(Homo["Snps"].median(), 1)
        homo_mean = round(Homo["Snps"].mean(), 1)
        homo_min = round(Homo["Snps"].min(), 1)
        homo_max = round(Homo["Snps"].max(), 1)

    All_quant = All_quant.fillna(1)
    Het_quant = Het_quant.fillna(1)
    Homo_quant = Homo_quant.fillna(1)

    # write to output
    sys.stderr.write(f"""

 -- SNPs/Kbp Statistics --

 S\tGen\tHet\tHomo
 Median\t{all_median}\t{het_median}\t{homo_median}
 Mean\t{all_mean}\t{het_mean}\t{homo_mean}
 Max\t{all_max}\t{het_max}\t{homo_max}
 Min\t{all_min}\t{het_min}\t{homo_min}

 -- SNPs/Kbp Quantiles --

 Q\tGen\tHet\tHomo
 5%\t{round(All_quant["Snps"].loc[0.05], 1)}\t{round(Het_quant["Snps"].loc[0.05], 1)}\t{round(Homo_quant["Snps"].loc[0.05], 1)}
 10%\t{round(All_quant["Snps"].loc[0.10], 1)}\t{round(Het_quant["Snps"].loc[0.10], 1)}\t{round(Homo_quant["Snps"].loc[0.10], 1)}
 15%\t{round(All_quant["Snps"].loc[0.15], 1)}\t{round(Het_quant["Snps"].loc[0.15], 1)}\t{round(Homo_quant["Snps"].loc[0.15], 1)}
 50%\t{round(All_quant["Snps"].loc[0.50], 1)}\t{round(Het_quant["Snps"].loc[0.50], 1)}\t{round(Homo_quant["Snps"].loc[0.50], 1)}
 85%\t{round(All_quant["Snps"].loc[0.85], 1)}\t{round(Het_quant["Snps"].loc[0.85], 1)}\t{round(Homo_quant["Snps"].loc[0.85], 1)}
 90%\t{round(All_quant["Snps"].loc[0.90], 1)}\t{round(Het_quant["Snps"].loc[0.90], 1)}\t{round(Homo_quant["Snps"].loc[0.90], 1)}
 95%\t{round(All_quant["Snps"].loc[0.95], 1)}\t{round(Het_quant["Snps"].loc[0.95], 1)}\t{round(Homo_quant["Snps"].loc[0.95], 1)}

""")

if __name__ == "__main__":
    main(args)
